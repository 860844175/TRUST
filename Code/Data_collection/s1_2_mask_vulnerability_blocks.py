import json
import pickle
import os
import re
from glob import glob
import argparse
from vllm import LLM, SamplingParams
import tiktoken
from tqdm import tqdm

"""
Stage s1_2: Identify risky code blocks within each full function and replace them with <MASK> tokens.

This runs after undefined-element retrieval:
  /home/jyu7/anaconda3/envs/Responsible/main/code/retrieval/retrieve_undefined_element.py

Input:
  - A list of tuples, each containing:
      (repo, sha, full_diff_text, changed_file, prefix_function, fix_function)
Output:
  - A pickle of LLM-generated masked versions of each prefix function.
"""

# System prompt guiding the LLM to identify and mask vulnerable code segments
system_prompt = """
You are an expert in C programming and software security.

## Task Overview
Your goal is to:
1. Identify distinct code modifications in the commit.
2. Extract relevant **line-based** contextual code segments around each modification.
3. Generate a masked version of the prefix function, replacing each risky block with `<MASK_[id]>`.
4. Ensure the masked output retains all unmodified code exactly as in the prefix.

## Task Details

### Task 1: Identify Modifications
- Use the commit diff to locate each added or modified code segment.
- Exclude blank lines.
- For each modification, output the exact prefix and fix snippets.

**Format:**
`task1 code modification X: prefix: <snippet> fix: <snippet>`

### Task 2: Context Extraction
- For each snippet from Task 1, capture the full line(s) in the prefix code that encompass the change.

**Format:**
`task2 code modification X: prefix: <line(s)> fix: <line(s)>`

### Task 3: Apply Masks
- In the prefix function code, replace each Task 2 segment with `<MASK_X>`.
- Do not include comments.
- After masking, verify that all non-`<MASK>` code matches the original prefix.

**Final Output:**  
The fully masked prefix function.
"""

# Template to wrap system + user messages for each function
prompt_template = """<|begin_of_text|><|start_header_id|>system<|end_header_id|>
{system}
<|eot_id|><|start_header_id|>user<|end_header_id|>

Here is the commit info, the full prefix function, and the full fix function.  
Please perform Tasks 1–3 as described.

#### Commit Info:
```

{commit\_info}

```

#### Prefix Function:
```

{prefix\_code}

```

#### Fix Function:
```

{fix\_code}

```

<|eot_id|><|start_header_id|>assistant<|end_header_id|>
"""

def main(input_dataset, output_path):
    """
    For each (repo, sha, diff, file, prefix, fix) in input_dataset:
      1. Render the LLM prompt by filling in commit info, prefix, and fix.
      2. Batch all prompts and call the LLM.
      3. Collect and pickle the masked-function outputs.
    """
    # Build a list of prompts for the entire dataset
    prompts = []
    for entry in input_dataset:
        repo, sha, full_diff, changed_file, prefix_fn, fix_fn = entry
        # We include only the commit header + message, not the full diff, in the "commit_info" field
        commit_header = "\n".join(full_diff.splitlines()[:10])  # adjust if needed
        prompts.append(
            prompt_template.format(
                system=system_prompt,
                commit_info=commit_header,
                prefix_code=prefix_fn,
                fix_code=fix_fn
            )
        )

    print(f"Generated {len(prompts)} prompts; invoking LLM...")

    # Initialize the LLM
    model_id = "meta-llama/Llama-3.1-70B-Instruct"
    llm = LLM(
        model=model_id,
        tensor_parallel_size=4,
        disable_custom_all_reduce=True,
        download_dir="/home/jyu7/"
    )
    sampling_params = SamplingParams(
        temperature=0.8,
        top_p=0.9,
        max_tokens=40960
    )

    # Run inference in batches via tqdm for progress
    masked_results = []
    for batch_start in range(0, len(prompts), 32):
        batch = prompts[batch_start:batch_start+32]
        outputs = llm.generate(batch, sampling_params)
        # Extract text from each output object
        for out in outputs:
            masked_results.append(out.outputs[0].text.strip())

    # Save the list of masked function strings
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, "wb") as f:
        pickle.dump(masked_results, f)

    print(f"Saved {len(masked_results)} masked functions to {output_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Stage s1_2: mask vulnerability blocks")
    parser.add_argument(
        "--reponame", type=str, required=True,
        help="Repository name, e.g. FFmpeg-FFmpeg or Android/kernel-common"
    )
    args = parser.parse_args()

    # Load the updated commits from stage s1_1
    input_path = f"../../automated_data/repo/{args.reponame}/s1/s1_1_security_commits_updated.pkl"
    input_dataset = pickle.load(open(input_path, "rb"))

    # Define where to write the masked results
    output_path = f"../../automated_data/repo/{args.reponame}/s1/s1_2_security_commits_blank_results.pkl"

    main(input_dataset, output_path)

